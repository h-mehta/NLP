{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trax : Ungraded Lecture Notebook\n",
    "\n",
    "In this notebook you'll get to know about the Trax framework and learn about some of its basic building blocks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Why Trax and not TensorFlow or PyTorch?\n",
    "\n",
    "TensorFlow and PyTorch are both extensive frameworks that can do almost anything in deep learning. They offer a lot of flexibility, but that often means verbosity of syntax and extra time to code.\n",
    "\n",
    "Trax is much more concise. It runs on a TensorFlow backend but allows you to train models with 1 line commands. Trax also runs end to end, allowing you to get data, model and train all with a single terse statements. This means you can focus on learning, instead of spending hours on the idiosyncrasies of big framework implementation.\n",
    "\n",
    "### Why not Keras then?\n",
    "\n",
    "Keras is now part of Tensorflow itself from 2.0 onwards. Also, trax is good for implementing new state of the art algorithms like Transformers, Reformers, BERT because it is actively maintained by Google Brain Team for advanced deep learning tasks. It runs smoothly on CPUs,GPUs and TPUs as well with comparatively lesser modifications in code.\n",
    "\n",
    "### How to Code in Trax\n",
    "Building models in Trax relies on 2 key concepts:- **layers** and **combinators**.\n",
    "Trax layers are simple objects that process data and perform computations. They can be chained together into composite layers using Trax combinators, allowing you to build layers and models of any complexity.\n",
    "\n",
    "### Trax, JAX, TensorFlow and Tensor2Tensor\n",
    "\n",
    "You already know that Trax uses Tensorflow as a backend, but it also uses the JAX library to speed up computation too. You can view JAX as an enhanced and optimized version of numpy. \n",
    "\n",
    "**Watch out for assignments which import `import trax.fastmath.numpy as np`. If you see this line, remember that when calling `np` you are really calling Trax’s version of numpy that is compatible with JAX.**\n",
    "\n",
    "As a result of this, where you used to encounter the type `numpy.ndarray` now you will find the type `jax.interpreters.xla.DeviceArray`.\n",
    "\n",
    "Tensor2Tensor is another name you might have heard. It started as an end to end solution much like how Trax is designed, but it grew unwieldy and complicated. So you can view Trax as the new improved version that operates much faster and simpler.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\n",
    "- JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Trax\n",
    "\n",
    "Trax has dependencies on JAX and some libraries like JAX which are yet to be supported in [Windows](https://github.com/google/jax/blob/1bc5896ee4eab5d7bb4ec6f161d8b2abb30557be/README.md#installation) but work well in Ubuntu and MacOS. We would suggest that if you are working on Windows, try to install Trax on WSL2. \n",
    "\n",
    "Official maintained documentation - [trax-ml](https://trax-ml.readthedocs.io/en/latest/) not to be confused with this [TraX](https://trax.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trax==1.3.9 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (1.3.9)\n",
      "Requirement already satisfied: absl-py in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (1.4.0)\n",
      "Requirement already satisfied: funcsigs in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (1.0.2)\n",
      "Requirement already satisfied: gin-config in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (0.5.0)\n",
      "Requirement already satisfied: gym in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (0.26.2)\n",
      "Requirement already satisfied: jax in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (0.4.13)\n",
      "Requirement already satisfied: jaxlib in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (0.4.13)\n",
      "Requirement already satisfied: matplotlib in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (3.7.1)\n",
      "Requirement already satisfied: numpy in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (1.23.5)\n",
      "Requirement already satisfied: psutil in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (5.9.5)\n",
      "Requirement already satisfied: scipy in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (1.11.0)\n",
      "Requirement already satisfied: six in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (1.16.0)\n",
      "Requirement already satisfied: t5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (0.9.4)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (4.9.2)\n",
      "Requirement already satisfied: tensorflow-text in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax==1.3.9) (2.12.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from gym->trax==1.3.9) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from gym->trax==1.3.9) (0.0.8)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from jax->trax==1.3.9) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from jax->trax==1.3.9) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax==1.3.9) (2.8.2)\n",
      "Requirement already satisfied: babel in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (2.12.1)\n",
      "Requirement already satisfied: editdistance in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (0.6.2)\n",
      "Requirement already satisfied: immutabledict in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (2.2.4)\n",
      "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (0.1.21)\n",
      "Requirement already satisfied: nltk in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (2.0.2)\n",
      "Requirement already satisfied: rouge-score>=0.1.2 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (0.1.99)\n",
      "Requirement already satisfied: seqio-nightly in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (0.0.15.dev20230627)\n",
      "Requirement already satisfied: tfds-nightly in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (4.9.2.dev202306270046)\n",
      "Requirement already satisfied: transformers>=2.7.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from t5->trax==1.3.9) (4.30.2)\n",
      "Requirement already satisfied: array-record in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (0.4.0)\n",
      "Requirement already satisfied: click in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (1.3.0)\n",
      "Requirement already satisfied: promise in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (3.20.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (1.13.1)\n",
      "Requirement already satisfied: termcolor in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (2.3.0)\n",
      "Requirement already satisfied: toml in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (4.65.0)\n",
      "Requirement already satisfied: wrapt in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax==1.3.9) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-text->trax==1.3.9) (0.13.0)\n",
      "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-text->trax==1.3.9) (2.12.0)\n",
      "Requirement already satisfied: importlib_resources in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax==1.3.9) (5.12.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax==1.3.9) (4.6.3)\n",
      "Requirement already satisfied: zipp in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax==1.3.9) (3.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from mesh-tensorflow[transformer]>=0.1.13->t5->trax==1.3.9) (0.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.9) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.9) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.9) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.9) (2023.5.7)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (16.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (68.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.32.0)\n",
      "Requirement already satisfied: filelock in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from transformers>=2.7.0->t5->trax==1.3.9) (0.3.1)\n",
      "Requirement already satisfied: joblib in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from nltk->t5->trax==1.3.9) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from pandas->t5->trax==1.3.9) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from pandas->t5->trax==1.3.9) (2023.3)\n",
      "Requirement already satisfied: portalocker in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from sacrebleu->t5->trax==1.3.9) (2.7.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from sacrebleu->t5->trax==1.3.9) (0.9.0)\n",
      "Requirement already satisfied: colorama in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from sacrebleu->t5->trax==1.3.9) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from sacrebleu->t5->trax==1.3.9) (4.9.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from scikit-learn->t5->trax==1.3.9) (3.1.0)\n",
      "Requirement already satisfied: clu in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from seqio-nightly->t5->trax==1.3.9) (0.0.9)\n",
      "Requirement already satisfied: pyglove in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from seqio-nightly->t5->trax==1.3.9) (0.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets->trax==1.3.9) (1.59.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.40.0)\n",
      "Requirement already satisfied: fsspec in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=2.7.0->t5->trax==1.3.9) (2023.6.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.3.6)\n",
      "Requirement already satisfied: flax in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from clu->seqio-nightly->t5->trax==1.3.9) (0.6.11)\n",
      "Requirement already satisfied: ml-collections in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from clu->seqio-nightly->t5->trax==1.3.9) (0.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (4.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (2.1.3)\n",
      "Requirement already satisfied: msgpack in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from flax->clu->seqio-nightly->t5->trax==1.3.9) (1.0.5)\n",
      "Requirement already satisfied: optax in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from flax->clu->seqio-nightly->t5->trax==1.3.9) (0.1.5)\n",
      "Requirement already satisfied: orbax-checkpoint in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from flax->clu->seqio-nightly->t5->trax==1.3.9) (0.2.6)\n",
      "Requirement already satisfied: tensorstore in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from flax->clu->seqio-nightly->t5->trax==1.3.9) (0.1.39)\n",
      "Requirement already satisfied: rich>=11.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from flax->clu->seqio-nightly->t5->trax==1.3.9) (13.4.2)\n",
      "Requirement already satisfied: contextlib2 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from ml-collections->clu->seqio-nightly->t5->trax==1.3.9) (21.6.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax==1.3.9) (3.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from rich>=11.1->flax->clu->seqio-nightly->t5->trax==1.3.9) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from rich>=11.1->flax->clu->seqio-nightly->t5->trax==1.3.9) (2.15.1)\n",
      "Requirement already satisfied: chex>=0.1.5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from optax->flax->clu->seqio-nightly->t5->trax==1.3.9) (0.1.8)\n",
      "Requirement already satisfied: cached_property in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from orbax-checkpoint->flax->clu->seqio-nightly->t5->trax==1.3.9) (1.5.2)\n",
      "Requirement already satisfied: nest_asyncio in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from orbax-checkpoint->flax->clu->seqio-nightly->t5->trax==1.3.9) (1.5.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from chex>=0.1.5->optax->flax->clu->seqio-nightly->t5->trax==1.3.9) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->clu->seqio-nightly->t5->trax==1.3.9) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install trax==1.3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trax in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (1.3.9)\n",
      "Collecting trax\n",
      "  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (1.4.0)\n",
      "Requirement already satisfied: funcsigs in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (1.0.2)\n",
      "Requirement already satisfied: gin-config in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (0.5.0)\n",
      "Requirement already satisfied: gym in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (0.26.2)\n",
      "Requirement already satisfied: jax in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (0.4.13)\n",
      "Requirement already satisfied: jaxlib in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (0.4.13)\n",
      "Requirement already satisfied: matplotlib in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (3.7.1)\n",
      "Requirement already satisfied: numpy in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (1.23.5)\n",
      "Requirement already satisfied: psutil in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (5.9.5)\n",
      "Requirement already satisfied: scipy in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (1.11.0)\n",
      "Requirement already satisfied: six in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (4.9.2)\n",
      "Requirement already satisfied: tensorflow-text in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from trax) (2.12.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from gym->trax) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from gym->trax) (0.0.8)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from jax->trax) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from jax->trax) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from matplotlib->trax) (2.8.2)\n",
      "Requirement already satisfied: array-record in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (0.4.0)\n",
      "Requirement already satisfied: click in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (1.3.0)\n",
      "Requirement already satisfied: promise in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (3.20.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (1.13.1)\n",
      "Requirement already satisfied: termcolor in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (2.3.0)\n",
      "Requirement already satisfied: toml in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (4.65.0)\n",
      "Requirement already satisfied: wrapt in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-datasets->trax) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-text->trax) (0.13.0)\n",
      "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-text->trax) (2.12.0)\n",
      "Requirement already satisfied: importlib_resources in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (5.12.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (4.6.3)\n",
      "Requirement already satisfied: zipp in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->trax) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2023.5.7)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (16.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (68.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.32.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.59.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->trax) (3.2.2)\n",
      "Installing collected packages: trax\n",
      "  Attempting uninstall: trax\n",
      "    Found existing installation: trax 1.3.9\n",
      "    Uninstalling trax-1.3.9:\n",
      "      Successfully uninstalled trax-1.3.9\n",
      "Successfully installed trax-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # regular ol' numpy\n",
    "\n",
    "from trax import layers as tl  # core building block\n",
    "from trax import shapes  # data signatures: dimensionality and type\n",
    "from trax import fastmath  # uses jax, offers numpy on steroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trax                          1.4.1\r\n"
     ]
    }
   ],
   "source": [
    "# Trax version 1.3.9 or better \n",
    "!pip list | grep trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "Layers are the core building blocks in Trax or as mentioned in the lectures, they are the base classes.\n",
    "\n",
    "They take inputs, compute functions/custom calculations and return outputs.\n",
    "\n",
    "You can also inspect layer properties. Let me show you some examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu Layer\n",
    "First let's see how to build a relu activation function as a layer. A layer like this is one of the simplest types. Notice there is no object initialization so it works just like a math function.\n",
    "\n",
    "**Note: Activation functions are also layers in Trax, which might look odd if you have been using other frameworks for a longer time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Properties --\n",
      "name : Serial\n",
      "expected inputs : 1\n",
      "promised outputs : 1 \n",
      "\n",
      "-- Inputs --\n",
      "x : [-2 -1  0  1  2] \n",
      "\n",
      "-- Outputs --\n",
      "y : [0 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Layers\n",
    "# Create a relu trax layer\n",
    "relu = tl.Relu()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", relu.name)\n",
    "print(\"expected inputs :\", relu.n_in)\n",
    "print(\"promised outputs :\", relu.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = relu(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Layer\n",
    "Now let's check how to build a layer that takes 2 inputs. Notice the change in the expected inputs property from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Properties --\n",
      "name : Concatenate\n",
      "expected inputs : 2\n",
      "promised outputs : 1 \n",
      "\n",
      "-- Inputs --\n",
      "x1 : [-10 -20 -30]\n",
      "x2 : [1. 2. 3.] \n",
      "\n",
      "-- Outputs --\n",
      "y : [-10. -20. -30.   1.   2.   3.]\n"
     ]
    }
   ],
   "source": [
    "# Create a concatenate trax layer\n",
    "concat = tl.Concatenate()\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", concat.name)\n",
    "print(\"expected inputs :\", concat.n_in)\n",
    "print(\"promised outputs :\", concat.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x1 :\", x1)\n",
    "print(\"x2 :\", x2, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = concat([x1, x2])\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers are Configurable\n",
    "You can change the default settings of layers. For example, you can change the expected inputs for a concatenate layer from 2 to 3 using the optional parameter `n_items`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Properties --\n",
      "name : Concatenate\n",
      "expected inputs : 3\n",
      "promised outputs : 1 \n",
      "\n",
      "-- Inputs --\n",
      "x1 : [-10 -20 -30]\n",
      "x2 : [1. 2. 3.]\n",
      "x3 : [0.99 1.98 2.97] \n",
      "\n",
      "-- Outputs --\n",
      "y : [-10.   -20.   -30.     1.     2.     3.     0.99   1.98   2.97]\n"
     ]
    }
   ],
   "source": [
    "# Configure a concatenate layer\n",
    "concat_3 = tl.Concatenate(n_items=3)  # configure the layer's expected inputs\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", concat_3.name)\n",
    "print(\"expected inputs :\", concat_3.n_in)\n",
    "print(\"promised outputs :\", concat_3.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "x3 = x2 * 0.99\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x1 :\", x1)\n",
    "print(\"x2 :\", x2)\n",
    "print(\"x3 :\", x3, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = concat_3([x1, x2, x3])\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: At any point,if you want to refer the function help/ look up the [documentation](https://trax-ml.readthedocs.io/en/latest/) or use help function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Concatenate in module trax.layers.combinators:\n",
      "\n",
      "class Concatenate(trax.layers.base.Layer)\n",
      " |  Concatenate(n_items=2, axis=-1)\n",
      " |  \n",
      " |  Concatenates a number of tensors into a single tensor.\n",
      " |  \n",
      " |  For example::\n",
      " |  \n",
      " |      x = np.array([1, 2])\n",
      " |      y = np.array([3, 4])\n",
      " |      z = np.array([5, 6])\n",
      " |      concat3 = tl.Concatenate(n_items=3)\n",
      " |      z = concat3((x, y, z))  # z = [1, 2, 3, 4, 5, 6]\n",
      " |  \n",
      " |  Use the `axis` argument to specify on which axis to concatenate the tensors.\n",
      " |  By default it's the last axis, `axis=-1`, and `n_items=2`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Concatenate\n",
      " |      trax.layers.base.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_items=2, axis=-1)\n",
      " |      Creates a partially initialized, unconnected layer instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        n_in: Number of inputs expected by this layer.\n",
      " |        n_out: Number of outputs promised by this layer.\n",
      " |        name: Class-like name for this layer; for use when printing this layer.\n",
      " |        sublayers_to_print: Sublayers to display when printing out this layer;\n",
      " |          if None (the default), display all sublayers.\n",
      " |  \n",
      " |  forward(self, xs)\n",
      " |      Executes this layer as part of a forward pass through the model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __call__(self, x, weights=None, state=None, rng=None)\n",
      " |      Makes layers callable; for use in tests or interactive settings.\n",
      " |      \n",
      " |      This convenience method helps library users play with, test, or otherwise\n",
      " |      probe the behavior of layers outside of a full training environment. It\n",
      " |      presents the layer as callable function from inputs to outputs, with the\n",
      " |      option of manually specifying weights and non-parameter state per individual\n",
      " |      call. For convenience, weights and non-parameter state are cached per layer\n",
      " |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,\n",
      " |      and acquiring non-empty values either by initialization or from values\n",
      " |      explicitly provided via the weights and state keyword arguments, in which\n",
      " |      case the old weights will be preserved, and the state will be updated.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: Weights or `None`; if `None`, use self's cached weights value.\n",
      " |        state: State or `None`; if `None`, use self's cached state value.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Zero or more output tensors, packaged as described in the `Layer` class\n",
      " |        docstring.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Renders this layer as a medium-detailed string, to help in debugging.\n",
      " |      \n",
      " |      Subclasses should aim for high-signal/low-noise when overriding this\n",
      " |      method.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A high signal-to-noise string representing this layer.\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Sets class attributes and protects from typos.\n",
      " |      \n",
      " |      In Trax layers, we only allow to set the following public attributes::\n",
      " |      \n",
      " |        - weights\n",
      " |        - state\n",
      " |        - rng\n",
      " |      \n",
      " |      This function prevents from setting other public attributes to avoid typos,\n",
      " |      for example, this is not possible and would be without this function::\n",
      " |      \n",
      " |        [typo]   layer.weighs = some_tensor\n",
      " |      \n",
      " |      If you need to set other public attributes in a derived class (which we\n",
      " |      do not recommend as in almost all cases it suffices to use a private\n",
      " |      attribute), override self._settable_attrs to include the attribute name.\n",
      " |      \n",
      " |      Args:\n",
      " |        attr: Name of the attribute to be set.\n",
      " |        value: Value to be assigned to the attribute.\n",
      " |  \n",
      " |  backward(self, inputs, output, grad, weights, state, new_state, rng)\n",
      " |      Custom backward pass to propagate gradients in a custom way.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensors; can be a (possibly nested) tuple.\n",
      " |        output: The result of running this layer on inputs.\n",
      " |        grad: Gradient signal computed based on subsequent layers; its structure\n",
      " |            and shape must match output.\n",
      " |        weights: This layer's weights.\n",
      " |        state: This layer's state prior to the current forward pass.\n",
      " |        new_state: This layer's state after the current forward pass.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The custom gradient signal for the input. Note that we need to return\n",
      " |        a gradient for each argument of forward, so it will usually be a tuple\n",
      " |        of signals: the gradient for inputs and weights.\n",
      " |  \n",
      " |  init(self, input_signature, rng=None, use_cache=False)\n",
      " |      Initializes weights/state of this layer and its sublayers recursively.\n",
      " |      \n",
      " |      Initialization creates layer weights and state, for layers that use them.\n",
      " |      It derives the necessary array shapes and data types from the layer's input\n",
      " |      signature, which is itself just shape and data type information.\n",
      " |      \n",
      " |      For layers without weights or state, this method safely does nothing.\n",
      " |      \n",
      " |      This method is designed to create weights/state only once for each layer\n",
      " |      instance, even if the same layer instance occurs in multiple places in the\n",
      " |      network. This enables weight sharing to be implemented as layer sharing.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or list/tuple of `ShapeDtype` instances.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |        use_cache: If `True`, and if this layer instance has already been\n",
      " |            initialized elsewhere in the network, then return special marker\n",
      " |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.\n",
      " |            Else return this layer's newly initialized weights and state.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  init_from_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Initializes this layer and its sublayers from a pickled checkpoint.\n",
      " |      \n",
      " |      In the common case (`weights_only=False`), the file must be a gziped pickled\n",
      " |      dictionary containing items with keys `'flat_weights', `'flat_state'` and\n",
      " |      `'input_signature'`, which are used to initialize this layer.\n",
      " |      If `input_signature` is specified, it's used instead of the one in the file.\n",
      " |      If `weights_only` is `True`, the dictionary does not need to have the\n",
      " |      `'flat_state'` item and the state it not restored either.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, initialize only the layer's weights. Else\n",
      " |            initialize both weights and state.\n",
      " |        input_signature: Input signature to be used instead of the one from file.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  init_weights_and_state(self, input_signature)\n",
      " |      Initializes weights and state, to handle input with the given signature.\n",
      " |      \n",
      " |      A layer subclass must override this method if the layer uses weights or\n",
      " |      state. To initialize weights, set `self.weights` to desired (typically\n",
      " |      random) values. To initialize state (uncommon), set `self.state` to desired\n",
      " |      starting values.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: A `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or a list/tuple of `ShapeDtype` instances.\n",
      " |  \n",
      " |  output_signature(self, input_signature)\n",
      " |      Returns output signature this layer would give for `input_signature`.\n",
      " |  \n",
      " |  pure_fn(self, x, weights, state, rng, use_cache=False)\n",
      " |      Applies this layer as a pure function with no optional args.\n",
      " |      \n",
      " |      This method exposes the layer's computation as a pure function. This is\n",
      " |      especially useful for JIT compilation. Do not override, use `forward`\n",
      " |      instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: A tuple or list of trainable weights, with one element for this\n",
      " |            layer if this layer has no sublayers, or one for each sublayer if\n",
      " |            this layer has sublayers. If a layer (or sublayer) has no trainable\n",
      " |            weights, the corresponding weights element is an empty tuple.\n",
      " |        state: Layer-specific non-parameter state that can update between batches.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |        use_cache: if `True`, cache weights and state in the layer object; used\n",
      " |          to implement layer sharing in combinators.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)\n",
      " |        promised by this layer, and are packaged as described in the `Layer`\n",
      " |        class docstring.\n",
      " |  \n",
      " |  save_to_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Saves this layer and its sublayers to a pickled checkpoint.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, save only the layer's weights. Else\n",
      " |            save both weights and state.\n",
      " |        input_signature: Input signature to be used.\n",
      " |  \n",
      " |  weights_and_state_signature(self, input_signature, unsafe=False)\n",
      " |      Return a pair containing the signatures of weights and state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  has_backward\n",
      " |      Returns `True` if this layer provides its own custom backward pass code.\n",
      " |      \n",
      " |      A layer subclass that provides custom backward pass code (for custom\n",
      " |      gradients) must override this method to return `True`.\n",
      " |  \n",
      " |  n_in\n",
      " |      Returns how many tensors this layer expects as input.\n",
      " |  \n",
      " |  n_out\n",
      " |      Returns how many tensors this layer promises as output.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this layer.\n",
      " |  \n",
      " |  sublayers\n",
      " |      Returns a tuple containing this layer's sublayers; may be empty.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  rng\n",
      " |      Returns this layer's current single-use random number generator.\n",
      " |      \n",
      " |      Code that wants to base random samples on this generator must explicitly\n",
      " |      split off new generators from it. (See, for example, the `rng` setter code\n",
      " |      below.)\n",
      " |  \n",
      " |  state\n",
      " |      Returns a tuple containing this layer's state; may be empty.\n",
      " |      \n",
      " |      If the layer has sublayers, the state by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing sublayer states.\n",
      " |      Note that in this case self._state only marks which ones are shared.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns this layer's weights.\n",
      " |      \n",
      " |      Depending on the layer, the weights can be in the form of:\n",
      " |      \n",
      " |        - an empty tuple\n",
      " |        - a tensor (ndarray)\n",
      " |        - a nested structure of tuples and tensors\n",
      " |      \n",
      " |      If the layer has sublayers, the weights by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing the weights of sublayers.\n",
      " |      Note that in this case self._weights only marks which ones are shared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tl.Concatenate) #Uncomment this to see the function docstring with explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers can have Weights\n",
    "Some layer types include mutable weights and biases that are used in computation and training. Layers of this type require initialization before use.\n",
    "\n",
    "For example the `LayerNorm` layer calculates normalized data, that is also scaled by weights and biases. During initialization you pass the data shape and data type of the inputs, so the layer can initialize compatible arrays of weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function signature in module trax.shapes:\n",
      "\n",
      "signature(obj)\n",
      "    Returns a `ShapeDtype` signature for the given `obj`.\n",
      "    \n",
      "    A signature is either a `ShapeDtype` instance or a tuple of `ShapeDtype`\n",
      "    instances. Note that this function is permissive with respect to its inputs\n",
      "    (accepts lists or tuples or dicts, and underlying objects can be any type\n",
      "    as long as they have shape and dtype attributes) and returns the corresponding\n",
      "    nested structure of `ShapeDtype`.\n",
      "    \n",
      "    Args:\n",
      "      obj: An object that has `shape` and `dtype` attributes, or a list/tuple/dict\n",
      "          of such objects.\n",
      "    \n",
      "    Returns:\n",
      "      A corresponding nested structure of `ShapeDtype` instances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment any of them to see information regarding the function\n",
    "#help(tl.LayerNorm)\n",
    "help(shapes.signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages/trax/layers/normalization.py:141: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  scale = jnp.ones(features, dtype=input_signature.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal shape: (4,) Data Type: <class 'tuple'>\n",
      "Shapes Trax: ShapeDtype{shape:(4,), dtype:float64} Data Type: <class 'trax.shapes.ShapeDtype'>\n",
      "-- Properties --\n",
      "name : LayerNorm\n",
      "expected inputs : 1\n",
      "promised outputs : 1\n",
      "weights : [1. 1. 1. 1.]\n",
      "biases : [0. 0. 0. 0.] \n",
      "\n",
      "-- Inputs --\n",
      "x : [0. 1. 2. 3.]\n",
      "-- Outputs --\n",
      "y : [-1.3416404  -0.44721344  0.44721344  1.3416404 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshit/opt/anaconda3/envs/env1/lib/python3.11/site-packages/trax/layers/normalization.py:142: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  bias = jnp.zeros(features, dtype=input_signature.dtype)\n"
     ]
    }
   ],
   "source": [
    "# Layer initialization\n",
    "norm = tl.LayerNorm()\n",
    "# You first must know what the input data will look like\n",
    "x = np.array([0, 1, 2, 3], dtype=\"float\")\n",
    "\n",
    "# Use the input data signature to get shape and type for initializing weights and biases\n",
    "norm.init(shapes.signature(x)) # We need to convert the input datatype from usual tuple to trax ShapeDtype\n",
    "\n",
    "print(\"Normal shape:\",x.shape, \"Data Type:\",type(x.shape))\n",
    "print(\"Shapes Trax:\",shapes.signature(x),\"Data Type:\",type(shapes.signature(x)))\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", norm.name)\n",
    "print(\"expected inputs :\", norm.n_in)\n",
    "print(\"promised outputs :\", norm.n_out)\n",
    "# Weights and biases\n",
    "print(\"weights :\", norm.weights[0])\n",
    "print(\"biases :\", norm.weights[1], \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x)\n",
    "\n",
    "# Outputs\n",
    "y = norm(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "This is where things start getting more interesting!\n",
    "You can create your own custom layers too and define custom functions for computations by using `tl.Fn`. Let me show you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Fn in module trax.layers.base:\n",
      "\n",
      "Fn(name, f, n_out=1)\n",
      "    Returns a layer with no weights that applies the function `f`.\n",
      "    \n",
      "    `f` can take and return any number of arguments, and takes only positional\n",
      "    arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
      "    The following, for example, would create a layer that takes two inputs and\n",
      "    returns two outputs -- element-wise sums and maxima:\n",
      "    \n",
      "        `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
      "    \n",
      "    The layer's number of inputs (`n_in`) is automatically set to number of\n",
      "    positional arguments in `f`, but you must explicitly set the number of\n",
      "    outputs (`n_out`) whenever it's not the default value 1.\n",
      "    \n",
      "    Args:\n",
      "      name: Class-like name for the resulting layer; for use in debugging.\n",
      "      f: Pure function from input tensors to output tensors, where each input\n",
      "          tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
      "          Output tensors must be packaged as specified in the `Layer` class\n",
      "          docstring.\n",
      "      n_out: Number of outputs promised by the layer; default value 1.\n",
      "    \n",
      "    Returns:\n",
      "      Layer executing the function `f`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tl.Fn) # Uncomment to see information regarding the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Properties --\n",
      "name : TimesTwo\n",
      "expected inputs : 1\n",
      "promised outputs : 1 \n",
      "\n",
      "-- Inputs --\n",
      "x : [1 2 3] \n",
      "\n",
      "-- Outputs --\n",
      "y : [2 4 6]\n"
     ]
    }
   ],
   "source": [
    "# Define a custom layer\n",
    "# In this example you will create a layer to calculate the input times 2\n",
    "\n",
    "def TimesTwo():\n",
    "    layer_name = \"TimesTwo\" #don't forget to give your custom layer a name to identify\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x):\n",
    "        return x * 2\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "\n",
    "# Test it\n",
    "times_two = TimesTwo()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", times_two.name)\n",
    "print(\"expected inputs :\", times_two.n_in)\n",
    "print(\"promised outputs :\", times_two.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([1, 2, 3])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = times_two(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinators\n",
    "You can combine layers to build more complex layers. Trax provides a set of objects named combinator layers to make this happen. Combinators are themselves layers, so behavior commutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial Combinator\n",
    "This is the most common and easiest to use. For example could build a simple neural network by combining layers into a single layer using the `Serial` combinator. This new layer then acts just like a single layer, so you can inspect intputs, outputs and weights. Or even combine it into another layer! Combinators can then be used as trainable models. _Try adding more layers_\n",
    "\n",
    "**Note: As you must have guessed, if there is serial combinator, there must be a parallel combinator as well. Do try to explore about combinators and other layers from the trax documentation and look at the repo to understand how these layers are written.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Serial in module trax.layers.combinators:\n",
      "\n",
      "class Serial(trax.layers.base.Layer)\n",
      " |  Serial(*sublayers, name=None, sublayers_to_print=None)\n",
      " |  \n",
      " |  Combinator that applies layers serially (by function composition).\n",
      " |  \n",
      " |  This combinator is commonly used to construct deep networks, e.g., like this::\n",
      " |  \n",
      " |      mlp = tl.Serial(\n",
      " |        tl.Dense(128),\n",
      " |        tl.Relu(),\n",
      " |        tl.Dense(10),\n",
      " |      )\n",
      " |  \n",
      " |  A Serial combinator uses stack semantics to manage data for its sublayers.\n",
      " |  Each sublayer sees only the inputs it needs and returns only the outputs it\n",
      " |  has generated. The sublayers interact via the data stack. For instance, a\n",
      " |  sublayer k, following sublayer j, gets called with the data stack in the\n",
      " |  state left after layer j has applied. The Serial combinator then:\n",
      " |  \n",
      " |    - takes n_in items off the top of the stack (n_in = k.n_in) and calls\n",
      " |      layer k, passing those items as arguments; and\n",
      " |  \n",
      " |    - takes layer k's n_out return values (n_out = k.n_out) and pushes\n",
      " |      them onto the data stack.\n",
      " |  \n",
      " |  A Serial instance with no sublayers acts as a special-case (but useful)\n",
      " |  1-input 1-output no-op.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Serial\n",
      " |      trax.layers.base.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *sublayers, name=None, sublayers_to_print=None)\n",
      " |      Creates a partially initialized, unconnected layer instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        n_in: Number of inputs expected by this layer.\n",
      " |        n_out: Number of outputs promised by this layer.\n",
      " |        name: Class-like name for this layer; for use when printing this layer.\n",
      " |        sublayers_to_print: Sublayers to display when printing out this layer;\n",
      " |          if None (the default), display all sublayers.\n",
      " |  \n",
      " |  forward(self, xs)\n",
      " |      Executes this layer as part of a forward pass through the model.\n",
      " |  \n",
      " |  init_weights_and_state(self, input_signature)\n",
      " |      Initializes weights and state for inputs with the given signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __call__(self, x, weights=None, state=None, rng=None)\n",
      " |      Makes layers callable; for use in tests or interactive settings.\n",
      " |      \n",
      " |      This convenience method helps library users play with, test, or otherwise\n",
      " |      probe the behavior of layers outside of a full training environment. It\n",
      " |      presents the layer as callable function from inputs to outputs, with the\n",
      " |      option of manually specifying weights and non-parameter state per individual\n",
      " |      call. For convenience, weights and non-parameter state are cached per layer\n",
      " |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,\n",
      " |      and acquiring non-empty values either by initialization or from values\n",
      " |      explicitly provided via the weights and state keyword arguments, in which\n",
      " |      case the old weights will be preserved, and the state will be updated.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: Weights or `None`; if `None`, use self's cached weights value.\n",
      " |        state: State or `None`; if `None`, use self's cached state value.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Zero or more output tensors, packaged as described in the `Layer` class\n",
      " |        docstring.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Renders this layer as a medium-detailed string, to help in debugging.\n",
      " |      \n",
      " |      Subclasses should aim for high-signal/low-noise when overriding this\n",
      " |      method.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A high signal-to-noise string representing this layer.\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Sets class attributes and protects from typos.\n",
      " |      \n",
      " |      In Trax layers, we only allow to set the following public attributes::\n",
      " |      \n",
      " |        - weights\n",
      " |        - state\n",
      " |        - rng\n",
      " |      \n",
      " |      This function prevents from setting other public attributes to avoid typos,\n",
      " |      for example, this is not possible and would be without this function::\n",
      " |      \n",
      " |        [typo]   layer.weighs = some_tensor\n",
      " |      \n",
      " |      If you need to set other public attributes in a derived class (which we\n",
      " |      do not recommend as in almost all cases it suffices to use a private\n",
      " |      attribute), override self._settable_attrs to include the attribute name.\n",
      " |      \n",
      " |      Args:\n",
      " |        attr: Name of the attribute to be set.\n",
      " |        value: Value to be assigned to the attribute.\n",
      " |  \n",
      " |  backward(self, inputs, output, grad, weights, state, new_state, rng)\n",
      " |      Custom backward pass to propagate gradients in a custom way.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensors; can be a (possibly nested) tuple.\n",
      " |        output: The result of running this layer on inputs.\n",
      " |        grad: Gradient signal computed based on subsequent layers; its structure\n",
      " |            and shape must match output.\n",
      " |        weights: This layer's weights.\n",
      " |        state: This layer's state prior to the current forward pass.\n",
      " |        new_state: This layer's state after the current forward pass.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The custom gradient signal for the input. Note that we need to return\n",
      " |        a gradient for each argument of forward, so it will usually be a tuple\n",
      " |        of signals: the gradient for inputs and weights.\n",
      " |  \n",
      " |  init(self, input_signature, rng=None, use_cache=False)\n",
      " |      Initializes weights/state of this layer and its sublayers recursively.\n",
      " |      \n",
      " |      Initialization creates layer weights and state, for layers that use them.\n",
      " |      It derives the necessary array shapes and data types from the layer's input\n",
      " |      signature, which is itself just shape and data type information.\n",
      " |      \n",
      " |      For layers without weights or state, this method safely does nothing.\n",
      " |      \n",
      " |      This method is designed to create weights/state only once for each layer\n",
      " |      instance, even if the same layer instance occurs in multiple places in the\n",
      " |      network. This enables weight sharing to be implemented as layer sharing.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or list/tuple of `ShapeDtype` instances.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |        use_cache: If `True`, and if this layer instance has already been\n",
      " |            initialized elsewhere in the network, then return special marker\n",
      " |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.\n",
      " |            Else return this layer's newly initialized weights and state.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  init_from_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Initializes this layer and its sublayers from a pickled checkpoint.\n",
      " |      \n",
      " |      In the common case (`weights_only=False`), the file must be a gziped pickled\n",
      " |      dictionary containing items with keys `'flat_weights', `'flat_state'` and\n",
      " |      `'input_signature'`, which are used to initialize this layer.\n",
      " |      If `input_signature` is specified, it's used instead of the one in the file.\n",
      " |      If `weights_only` is `True`, the dictionary does not need to have the\n",
      " |      `'flat_state'` item and the state it not restored either.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, initialize only the layer's weights. Else\n",
      " |            initialize both weights and state.\n",
      " |        input_signature: Input signature to be used instead of the one from file.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  output_signature(self, input_signature)\n",
      " |      Returns output signature this layer would give for `input_signature`.\n",
      " |  \n",
      " |  pure_fn(self, x, weights, state, rng, use_cache=False)\n",
      " |      Applies this layer as a pure function with no optional args.\n",
      " |      \n",
      " |      This method exposes the layer's computation as a pure function. This is\n",
      " |      especially useful for JIT compilation. Do not override, use `forward`\n",
      " |      instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: A tuple or list of trainable weights, with one element for this\n",
      " |            layer if this layer has no sublayers, or one for each sublayer if\n",
      " |            this layer has sublayers. If a layer (or sublayer) has no trainable\n",
      " |            weights, the corresponding weights element is an empty tuple.\n",
      " |        state: Layer-specific non-parameter state that can update between batches.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |        use_cache: if `True`, cache weights and state in the layer object; used\n",
      " |          to implement layer sharing in combinators.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)\n",
      " |        promised by this layer, and are packaged as described in the `Layer`\n",
      " |        class docstring.\n",
      " |  \n",
      " |  save_to_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Saves this layer and its sublayers to a pickled checkpoint.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickled weights/state file.\n",
      " |        weights_only: If `True`, save only the layer's weights. Else\n",
      " |            save both weights and state.\n",
      " |        input_signature: Input signature to be used.\n",
      " |  \n",
      " |  weights_and_state_signature(self, input_signature, unsafe=False)\n",
      " |      Return a pair containing the signatures of weights and state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  has_backward\n",
      " |      Returns `True` if this layer provides its own custom backward pass code.\n",
      " |      \n",
      " |      A layer subclass that provides custom backward pass code (for custom\n",
      " |      gradients) must override this method to return `True`.\n",
      " |  \n",
      " |  n_in\n",
      " |      Returns how many tensors this layer expects as input.\n",
      " |  \n",
      " |  n_out\n",
      " |      Returns how many tensors this layer promises as output.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this layer.\n",
      " |  \n",
      " |  sublayers\n",
      " |      Returns a tuple containing this layer's sublayers; may be empty.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  rng\n",
      " |      Returns this layer's current single-use random number generator.\n",
      " |      \n",
      " |      Code that wants to base random samples on this generator must explicitly\n",
      " |      split off new generators from it. (See, for example, the `rng` setter code\n",
      " |      below.)\n",
      " |  \n",
      " |  state\n",
      " |      Returns a tuple containing this layer's state; may be empty.\n",
      " |      \n",
      " |      If the layer has sublayers, the state by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing sublayer states.\n",
      " |      Note that in this case self._state only marks which ones are shared.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns this layer's weights.\n",
      " |      \n",
      " |      Depending on the layer, the weights can be in the form of:\n",
      " |      \n",
      " |        - an empty tuple\n",
      " |        - a tensor (ndarray)\n",
      " |        - a nested structure of tuples and tensors\n",
      " |      \n",
      " |      If the layer has sublayers, the weights by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing the weights of sublayers.\n",
      " |      Note that in this case self._weights only marks which ones are shared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment any of them to see information regarding the function\n",
    "help(tl.Serial)\n",
    "# help(tl.Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function LogSoftmax in module trax.layers.core:\n",
      "\n",
      "LogSoftmax(axis=-1)\n",
      "    Returns a layer that applies log softmax along one tensor axis.\n",
      "    \n",
      "    Note that the implementation actually computes x - LogSumExp(x),\n",
      "    which is mathematically equal to LogSoftmax(x).\n",
      "    \n",
      "    `LogSoftmax` acts on a group of values and normalizes them to look like a set\n",
      "    of log probability values. (Probability values must be non-negative, and as\n",
      "    a set must sum to 1. A group of log probability values can be seen as the\n",
      "    natural logarithm function applied to a set of probability values.)\n",
      "    \n",
      "    Args:\n",
      "      axis: Axis along which values are grouped for computing log softmax.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tl.LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Serial Model --\n",
      "Serial[\n",
      "  LayerNorm\n",
      "  Serial[\n",
      "    Relu\n",
      "  ]\n",
      "  TimesTwo\n",
      "  Dense_2\n",
      "  LogSoftmax\n",
      "] \n",
      "\n",
      "-- Properties --\n",
      "name : Serial\n",
      "sublayers : [LayerNorm, Serial[\n",
      "  Relu\n",
      "], TimesTwo, Dense_2, LogSoftmax]\n",
      "expected inputs : 1\n",
      "promised outputs : 1\n",
      "weights & biases: ((Array([1, 1, 1, 1, 1], dtype=int32), Array([0, 0, 0, 0, 0], dtype=int32)), ((), (), ()), (), (Array([[-0.31349212,  0.7690518 ],\n",
      "       [-0.8569411 ,  0.8336578 ],\n",
      "       [-0.37514165, -0.832523  ],\n",
      "       [ 0.70950645,  0.5865568 ],\n",
      "       [-0.07400881,  0.19007559]], dtype=float32), Array([-1.3147221e-07,  5.2099307e-07], dtype=float32)), ()) \n",
      "\n",
      "-- Inputs --\n",
      "x : [-2 -1  0  1  2] \n",
      "\n",
      "-- Outputs --\n",
      "y : [-1.0201817  -0.44711483]\n"
     ]
    }
   ],
   "source": [
    "# Serial combinator\n",
    "serial = tl.Serial(\n",
    "    tl.LayerNorm(),         # normalize input\n",
    "    tl.Relu(),              # convert negative values to zero\n",
    "    times_two,              # the custom layer you created above, multiplies the input recieved from above by 2\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    tl.Dense(n_units=2),  # try adding more layers. eg uncomment these lines\n",
    "#   tl.Dense(n_units=1),  # Binary classification, maybe? uncomment at your own peril\n",
    "    tl.LogSoftmax()       # Yes, LogSoftmax is also a layer\n",
    "    ### END CODE HERE\n",
    ")\n",
    "\n",
    "# Initialization\n",
    "x = np.array([-2, -1, 0, 1, 2]) #input\n",
    "serial.init(shapes.signature(x)) #initialising serial instance\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial,\"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out)\n",
    "print(\"weights & biases:\", serial.weights, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX\n",
    "Just remember to lookout for which numpy you are using, the regular ol' numpy or Trax's JAX compatible numpy. Both tend to use the alias np so watch those import blocks.\n",
    "\n",
    "**Note: There are certain things which are still not possible in fastmath.numpy which can be done in numpy so you will see in assignments we will switch between them to get our work done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good old numpy :  <class 'numpy.ndarray'> \n",
      "\n",
      "jax trax numpy :  <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "# Numpy vs fastmath.numpy have different data types\n",
    "# Regular ol' numpy\n",
    "x_numpy = np.array([1, 2, 3])\n",
    "print(\"good old numpy : \", type(x_numpy), \"\\n\")\n",
    "\n",
    "# Fastmath and jax numpy\n",
    "x_jax = fastmath.numpy.array([1, 2, 3])\n",
    "print(\"jax trax numpy : \", type(x_jax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Trax is a concise framework, built on TensorFlow, for end to end machine learning. The key building blocks are layers and combinators. This notebook is just a taste, but sets you up with some key inuitions to take forward into the rest of the course and assignments where you will build end to end models."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
